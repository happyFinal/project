{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296a89c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in /home/work/.local/lib/python3.8/site-packages (0.13.7)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.20.0)\n",
      "Requirement already satisfied: pathtools in /home/work/.local/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: setproctitle in /home/work/.local/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/work/.local/lib/python3.8/site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/work/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.26)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from wandb) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (59.5.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/work/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9663b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", \n",
    "                                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                                                    pad_token='<pad>', mask_token='<mask>')\n",
    "tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee679724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1583611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbfa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '구'\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "gen_ids = model.generate(input_ids, \n",
    "                         max_length=10, \n",
    "                         repetition_penalty=2.0, \n",
    "                         pad_token_id=tokenizer.pad_token_id,\n",
    "                         eos_token_id=tokenizer.eos_token_id,\n",
    "                         bos_token_id=tokenizer.bos_token_id,\n",
    "                         use_cache=True)\n",
    "\n",
    "generated = tokenizer.decode(gen_ids[0])\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d6cb1",
   "metadata": {},
   "source": [
    "# 여기부터 다른 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6770092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0aea1",
   "metadata": {},
   "source": [
    "[참고 링크](https://0goodmorning.tistory.com/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f96260",
   "metadata": {},
   "source": [
    "## fine tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d723c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['다시 만난 누난 예뻐\\n',\n",
       " 'i aint frontin\\n',\n",
       " 'Its been a while Im breaking out\\n',\n",
       " '이해할 수 없어 나를\\n',\n",
       " '이사간 대가는\\n',\n",
       " '째깍째깍 자꾸만\\n',\n",
       " '저하늘의 슬픔 속에\\n',\n",
       " '망설이던 시간들은 안녕\\n',\n",
       " '내 모습 내가 봐도 뿅 갈 것 같아\\n',\n",
       " '힘들다곤 내가 먼저 했는데\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"test_data.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    l = f.readlines()\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f40333",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f725ec39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['다시 만난 누난 예뻐',\n",
       " 'i aint frontin',\n",
       " 'Its been a while Im breaking out',\n",
       " '이해할 수 없어 나를',\n",
       " '이사간 대가는',\n",
       " '째깍째깍 자꾸만',\n",
       " '저하늘의 슬픔 속에',\n",
       " '망설이던 시간들은 안녕',\n",
       " '내 모습 내가 봐도 뿅 갈 것 같아',\n",
       " '힘들다곤 내가 먼저 했는데']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개행 문자 제거\n",
    "removed_n = [sentence.replace(\"\\n\", \"\") for sentence in l]\n",
    "removed_n[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e800e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['다시 만난 누난 예뻐',\n",
       " 'i aint frontin',\n",
       " 'Its been a while Im breaking out',\n",
       " '이해할 수 없어 나를',\n",
       " '이사간 대가는',\n",
       " '째깍째깍 자꾸만',\n",
       " '저하늘의 슬픔 속에',\n",
       " '망설이던 시간들은 안녕',\n",
       " '내 모습 내가 봐도 뿅 갈 것 같아',\n",
       " '힘들다곤 내가 먼저 했는데']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공백 제거\n",
    "removed_s = [sentence.strip() for sentence in removed_n]\n",
    "removed_s[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff48cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['다시 만난 누난 예뻐',\n",
       " 'i aint frontin',\n",
       " 'Its been a while Im breaking out',\n",
       " '이해할 수 없어 나를',\n",
       " '이사간 대가는',\n",
       " '째깍째깍 자꾸만',\n",
       " '저하늘의 슬픔 속에',\n",
       " '망설이던 시간들은 안녕',\n",
       " '내 모습 내가 봐도 뿅 갈 것 같아',\n",
       " '힘들다곤 내가 먼저 했는데']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1글자로 이뤄진 문장 제거\n",
    "removed_1 = [sentence for sentence in removed_s if len(sentence) > 1]\n",
    "removed_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71240252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198480"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed596d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\", padding='max_length',\n",
    "                                          max_len = 50,\n",
    "                                          add_special_tokens = True, \n",
    "                                          return_tensors=\"pt\",\n",
    "                                          truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63297a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (487 > 50). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[9427, 22004, 9669, 7058, 9182, 7722],\n",
       " [30261, 13612, 37415, 13063, 21225, 458, 9610],\n",
       " [10054,\n",
       "  24646,\n",
       "  13726,\n",
       "  443,\n",
       "  9714,\n",
       "  13612,\n",
       "  18896,\n",
       "  446,\n",
       "  25816,\n",
       "  10054,\n",
       "  451,\n",
       "  13726,\n",
       "  10435,\n",
       "  19008,\n",
       "  10929,\n",
       "  10288,\n",
       "  14197],\n",
       " [18637, 9025, 10811, 24692],\n",
       " [12667, 6826, 9026, 9932]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_input_ids = tokenizer(removed_1).input_ids\n",
    "tokenizer_input_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef297b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 17, 4, 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_length = [len(item) for item in tokenizer_input_ids]\n",
    "tokenized_length[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea0716a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/compat/_optional.py:161: UserWarning: Pandas requires version '2.7.1' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# check the length distribution of the list with x ticks divided by 10 tokens\n",
    "plt.hist(tokenized_length, bins=np.arange(0, max(tokenized_length)+1, 10))\n",
    "print(max(tokenized_length)+1)\n",
    "plt.xlabel(\"Length of the tokenized sentence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc575e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 50개 넘는 애들은 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55be80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_input_ids.sort(key=lambda x: len(x))\n",
    "while len(tokenizer_input_ids[-1]) >= 50:\n",
    "    tokenizer_input_ids.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98457949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9815,\n",
       " 14778,\n",
       " 18896,\n",
       " 443,\n",
       " 739,\n",
       " 27797,\n",
       " 18896,\n",
       " 443,\n",
       " 739,\n",
       " 27797,\n",
       " 18896,\n",
       " 443,\n",
       " 739,\n",
       " 27797,\n",
       " 33287,\n",
       " 411,\n",
       " 420,\n",
       " 15369,\n",
       " 421,\n",
       " 427,\n",
       " 424,\n",
       " 10403,\n",
       " 431,\n",
       " 411,\n",
       " 425,\n",
       " 11045,\n",
       " 411,\n",
       " 9772,\n",
       " 424,\n",
       " 411,\n",
       " 9707,\n",
       " 411,\n",
       " 407,\n",
       " 47717,\n",
       " 9924,\n",
       " 35548,\n",
       " 411,\n",
       " 408,\n",
       " 424,\n",
       " 424,\n",
       " 424,\n",
       " 10445,\n",
       " 31175,\n",
       " 22068,\n",
       " 426,\n",
       " 22068,\n",
       " 426,\n",
       " 22068,\n",
       " 426]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokenizer_input_ids[-1]))\n",
    "tokenizer_input_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba271616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_length = [len(item) for item in tokenizer_input_ids]\n",
    "tokenized_length[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01df4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# check the length distribution of the list with x ticks divided by 10 tokens\n",
    "plt.hist(tokenized_length, bins=np.arange(0, max(tokenized_length)+1, 10))\n",
    "print(max(tokenized_length)+1)\n",
    "plt.xlabel(\"Length of the tokenized sentence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04217eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size=128):\n",
    "    dataset = TextDataset(tokenizer=tokenizer,\n",
    "                         file_path=file_path,\n",
    "                         block_size=block_size,\n",
    "                         )\n",
    "    return dataset\n",
    "\n",
    "def load_data_collator(tokenizer, mlm=False):\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                   mlm=mlm)\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "532df54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 구글링 하면 다들 이 코드를 쓰지만\n",
    "# tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "\n",
    "# 허깅페이스 공식 사이트에는 이 코드로 나와서 이걸 사용\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\", padding='max_length',\n",
    "#                                           max_len = 100,\n",
    "#                                           add_special_tokens = True, \n",
    "#                                           return_tensors=\"pt\",\n",
    "#                                           truncation = True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aa4e375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/config.json from cache at /home/work/.cache/huggingface/transformers/13bb826cf24517d7849a701e02452715a67c5e560142be3d4735442b2a545809.6b384eec6effdd44287f67715cd55bd0dff2cf846d843b932b43ba7b632b8b1e\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/pytorch_model.bin from cache at /home/work/.cache/huggingface/transformers/495b405e3742953dbcc56685d1560fa02a2d86fc50b891868990a4471b06c934.4ebf112d34c2c8fc657866680005d92d21859c52c0ef5e941fa640129b2f8f88\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at skt/kogpt2-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Loading features from cached file cached_lm_GPT2TokenizerFast_128_test_data.txt [took 0.171 s]\n",
      "tokenizer config file saved in ./models2/tokenizer_config.json\n",
      "Special tokens file saved in ./models2/special_tokens_map.json\n",
      "Configuration saved in ./models2/config.json\n",
      "Model weights saved in ./models2/pytorch_model.bin\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 13037\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8150\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8150' max='8150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8150/8150 19:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.207100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.541900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.550500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.358400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.222600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models2/checkpoint-500\n",
      "Configuration saved in ./models2/checkpoint-500/config.json\n",
      "Model weights saved in ./models2/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-1000\n",
      "Configuration saved in ./models2/checkpoint-1000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-1500\n",
      "Configuration saved in ./models2/checkpoint-1500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-2000\n",
      "Configuration saved in ./models2/checkpoint-2000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-2500\n",
      "Configuration saved in ./models2/checkpoint-2500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-3000\n",
      "Configuration saved in ./models2/checkpoint-3000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-3500\n",
      "Configuration saved in ./models2/checkpoint-3500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-4000\n",
      "Configuration saved in ./models2/checkpoint-4000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-4500\n",
      "Configuration saved in ./models2/checkpoint-4500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-5000\n",
      "Configuration saved in ./models2/checkpoint-5000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-5500\n",
      "Configuration saved in ./models2/checkpoint-5500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-6000\n",
      "Configuration saved in ./models2/checkpoint-6000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-6500\n",
      "Configuration saved in ./models2/checkpoint-6500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-7000\n",
      "Configuration saved in ./models2/checkpoint-7000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-7500\n",
      "Configuration saved in ./models2/checkpoint-7500/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to ./models2/checkpoint-8000\n",
      "Configuration saved in ./models2/checkpoint-8000/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/checkpoint-8000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./models2\n",
      "Configuration saved in ./models2/config.json\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Model weights saved in ./models2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "\n",
    "def train(train_file_path, model_name, output_dir, overwrite_output_dir, per_device_train_batch_size, num_train_epochs, save_step, tokenizer):\n",
    "    train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "    data_collator = load_data_collator(tokenizer)\n",
    "    \n",
    "    tokenizer.save_pretrained(output_dir, legacy_format=False)\n",
    "    \n",
    "#     model = AutoModelForCausalLM.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "    model.save_pretrained(output_dir)\n",
    "    \n",
    "    training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                     overwrite_output_dir=overwrite_output_dir,\n",
    "                                     per_device_train_batch_size=per_device_train_batch_size,\n",
    "                                     num_train_epochs=num_train_epochs)\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                     args=training_args,\n",
    "                     data_collator=data_collator,\n",
    "                     train_dataset=train_dataset)\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    \n",
    "train_file_path = \"test_data.txt\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "output_dir = \"./models2\"\n",
    "overwrite_output_dir = False\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 5.0\n",
    "save_step = 500\n",
    "\n",
    "train(train_file_path=train_file_path,\n",
    "     model_name=model_name,\n",
    "     output_dir=output_dir,\n",
    "     overwrite_output_dir=overwrite_output_dir,\n",
    "     per_device_train_batch_size=per_device_train_batch_size,\n",
    "     num_train_epochs=num_train_epochs,\n",
    "     save_step=save_step,\n",
    "     tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98353323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "def generate_text(sequence, k, max_length):\n",
    "    model_path = \"./models2\"\n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f\"{sequence},\", return_tensors=\"pt\")\n",
    "    final_outputs = model.generate(ids, do_sample=True, max_length=max_length,\n",
    "                                  pad_token_id=model.config.pad_token_id,\n",
    "                                  top_k=50,\n",
    "                                  top_p=0.95)\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df967298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models2/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file ./models2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :친구\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Didn't find file ./models2/vocab.json. We won't load it.\n",
      "Didn't find file ./models2/merges.txt. We won't load it.\n",
      "Didn't find file ./models2/added_tokens.json. We won't load it.\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./models2/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models2/special_tokens_map.json\n",
      "loading file ./models2/tokenizer_config.json\n",
      "loading configuration file ./models2/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file ./models2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구, 힙합 클럽에서\n",
      "지루하다며 울다 보면\n",
      "그런 건 절대 못해 너란 놈은\n",
      "난 괜찮아 내 삶의 주인이 되려 해\n",
      "네 앞에선 \n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Didn't find file ./models2/vocab.json. We won't load it.\n",
      "Didn't find file ./models2/merges.txt. We won't load it.\n",
      "Didn't find file ./models2/added_tokens.json. We won't load it.\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./models2/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models2/special_tokens_map.json\n",
      "loading file ./models2/tokenizer_config.json\n",
      "loading configuration file ./models2/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file ./models2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구,\n",
      "오래 된 편지 한 장과\n",
      "그댈 위한 노랠 불러 봅니다\n",
      "Lets gets get set set\n",
      "그대 나를 떠난다고 말하지 마오\n",
      "아무\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Didn't find file ./models2/vocab.json. We won't load it.\n",
      "Didn't find file ./models2/merges.txt. We won't load it.\n",
      "Didn't find file ./models2/added_tokens.json. We won't load it.\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./models2/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models2/special_tokens_map.json\n",
      "loading file ./models2/tokenizer_config.json\n",
      "loading configuration file ./models2/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file ./models2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구,\n",
      "내 곁을 떠나갔는데\n",
      "우리 둘 만의 Dance\n",
      "아무 생각이나 말고\n",
      "그렇다고 내 삶이 끝나는 건 아니야\n",
      "이제 네가 없는 세상이 낯설어\n",
      "\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Didn't find file ./models2/vocab.json. We won't load it.\n",
      "Didn't find file ./models2/merges.txt. We won't load it.\n",
      "Didn't find file ./models2/added_tokens.json. We won't load it.\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./models2/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models2/special_tokens_map.json\n",
      "loading file ./models2/tokenizer_config.json\n",
      "loading configuration file ./models2/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file ./models2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구, 아빠는 나의 사랑아빠는 나의 딸\n",
      "내가 네가 아팠던 기억에\n",
      "그런 놈들 있지 난 다 알아\n",
      "when i fallin\n",
      "난 너에게\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Didn't find file ./models2/vocab.json. We won't load it.\n",
      "Didn't find file ./models2/merges.txt. We won't load it.\n",
      "Didn't find file ./models2/added_tokens.json. We won't load it.\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./models2/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models2/special_tokens_map.json\n",
      "loading file ./models2/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구, Ye\n",
      "사랑해줘서 고마워요\n",
      "이번만큼은 나를 사랑해준거야\n",
      "사랑해줘서 고마워\n",
      "아프게 해 아무것도 아닌\n",
      "또 너한테 또\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "sequence = \"친구\"\n",
    "max_len = 42\n",
    "print(\"input :\" + sequence)\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for i in range(5):\n",
    "    generate_text(sequence, max_len)\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "128b0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models2/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file ./models2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Didn't find file ./models2/vocab.json. We won't load it.\n",
      "Didn't find file ./models2/merges.txt. We won't load it.\n",
      "Didn't find file ./models2/added_tokens.json. We won't load it.\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./models2/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models2/special_tokens_map.json\n",
      "loading file ./models2/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가,\n",
      "나를 보며 웃을 수 있어서\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         list_samhaengshi\u001b[38;5;241m.\u001b[39mextend(list_decoded_sequences)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m list_samhaengshi\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmake_samhaengshi\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_letter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m가을잎\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_token_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mmake_samhaengshi\u001b[0;34m(input_letter, k, output_token_length)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m one_letter \u001b[38;5;129;01min\u001b[39;00m input_letter:\n\u001b[1;32m      4\u001b[0m     list_decoded_sequences \u001b[38;5;241m=\u001b[39m generate_text(one_letter, k\u001b[38;5;241m=\u001b[39mk, max_length\u001b[38;5;241m=\u001b[39moutput_token_length)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mlist_samhaengshi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_decoded_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m list_samhaengshi\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def make_samhaengshi(input_letter, k, output_token_length):\n",
    "    list_samhaengshi = []\n",
    "    for one_letter in input_letter:\n",
    "        list_decoded_sequences = generate_text(one_letter, k=k, max_length=output_token_length)\n",
    "        list_samhaengshi.extend(list_decoded_sequences)\n",
    "    return list_samhaengshi\n",
    "\n",
    "make_samhaengshi(input_letter=\"가을잎\", k=1, output_token_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05c5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65b193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f153e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred sentences given '너는 나의'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m input_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m너는 나의\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferred sentences given \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m inferred_sentences \u001b[38;5;241m=\u001b[39m infer_sentence(input_sentence, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, output_token_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m)\n\u001b[1;32m     35\u001b[0m inferred_sentences\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def infer_sentence(input_sentence, k, output_token_length, model):\n",
    "\n",
    "    # encode the sample sentence\n",
    "    input_ids = tokenizer.encode(\n",
    "        input_sentence, \n",
    "        add_special_tokens=False, \n",
    "        return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    # decode the output sequence and print its outcome\n",
    "    list_decoded_sequences = []\n",
    "    while len(list_decoded_sequences) < k:\n",
    "        # generate output sequence from the given encoded input sequence\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=input_ids.to(device), \n",
    "            do_sample=True, \n",
    "            max_length=output_token_length, \n",
    "            num_return_sequences=k\n",
    "            )\n",
    "\n",
    "        for index, generated_sequence in enumerate(output_sequences):\n",
    "            generated_sequence = generated_sequence.tolist()\n",
    "            # remove padding from the generated sequence\n",
    "            generated_sequence = generated_sequence[:generated_sequence.index(tokenizer.pad_token_id)]\n",
    "            decoded_sequence = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "            # print(f\"{index} : {decoded_sequence}\")\n",
    "            list_decoded_sequences.append(decoded_sequence)\n",
    "        list_decoded_sequences = list(set(list_decoded_sequences))\n",
    "    \n",
    "    return list_decoded_sequences\n",
    "\n",
    "input_sentence = \"너는 나의\"\n",
    "print(f\"Inferred sentences given '{input_sentence}'\")\n",
    "inferred_sentences = infer_sentence(input_sentence, k=10, output_token_length=42, model=model)\n",
    "inferred_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc21d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d60202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed74a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9b2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73353f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ad4bfb8",
   "metadata": {},
   "source": [
    "# 여기부터 다른 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b46469",
   "metadata": {},
   "source": [
    "[참고 링크](https://github.com/snoop2head/KoGPT-Joong-2/blob/main/finetune_kogpt_trinity.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37daea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = os.path.abspath(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa48fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from easydict import EasyDict\n",
    "\n",
    "# Initialize configuration\n",
    "CFG = EasyDict()\n",
    "\n",
    "# Dataset Config as constants\n",
    "CFG.DEBUG = False\n",
    "CFG.num_workers = 4\n",
    "CFG.train_batch_size = 16\n",
    "\n",
    "# Train configuration\n",
    "CFG.user_name = \"snoop2head\"\n",
    "today = datetime.now().strftime(\"%m%d_%H:%M\")\n",
    "CFG.file_base_name = f\"{CFG.user_name}_{today}\"\n",
    "CFG.model_dir = \"skt/ko-gpt-trinity-1.2B-v0.5\" # designate the model's name registered on huggingface: https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5\n",
    "CFG.max_token_length = 42\n",
    "CFG.learning_rate = 5e-5\n",
    "CFG.weight_decay = 1e-2 # https://paperswithcode.com/method/weight-decay and https://github.com/clovaai/AdamP\n",
    "\n",
    "# training steps configurations\n",
    "CFG.save_steps = 500\n",
    "CFG.early_stopping_patience = 5\n",
    "CFG.warmup_steps = 500\n",
    "CFG.logging_steps = 100\n",
    "CFG.evaluation_strategy = 'epoch'\n",
    "CFG.evaluation_steps = 500\n",
    "\n",
    "# Directory configuration\n",
    "CFG.result_dir = os.path.join(ROOT_PATH, \"results\")\n",
    "CFG.saved_model_dir = os.path.join(ROOT_PATH, \"best_models\")\n",
    "CFG.logging_dir = os.path.join(ROOT_PATH, \"logs\")\n",
    "CFG.baseline_dir = os.path.join(ROOT_PATH, 'baseline-code')\n",
    "\n",
    "print(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file from line by line\n",
    "def read_txt(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "# make sampling function from the list\n",
    "def sampling(list_lines:list, n:int) -> list:\n",
    "    # sampling\n",
    "    list_lines = np.random.choice(list_lines, n)\n",
    "    list_lines = list(list_lines)\n",
    "    return list_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0adb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from poetic_sentences_kor.txt\n",
    "path = os.path.join(\"test_data.txt\")\n",
    "list_loaded = read_txt(path)\n",
    "print(\"total dataset length:\", len(list_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get proportion of sentences where length is between 1 and 52\n",
    "min_char_length = 5\n",
    "max_char_length = 52\n",
    "list_to_use = list(filter(lambda x: len(x) > min_char_length and len(x) < max_char_length, list_loaded))\n",
    "\n",
    "print(f\"Length of dataset that is in between {min_char_length} and {max_char_length} is\" , len(list_to_use))\n",
    "print(f\"This is {round(len(list_to_use) / len(list_loaded) * 100, 2)} % of total dataset\")\n",
    "\n",
    "n = 20\n",
    "print(f\"Below are {n} samples of data to use\")\n",
    "sampling(list_to_use, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce66be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "# make post_process function\n",
    "def post_process(list_lines:list, stopwords) -> list:\n",
    "    # remove \\n\n",
    "    removed_lines = [line.strip() for line in list_lines]\n",
    "\n",
    "    # filter stopwords from the line item in list_lines using regex\n",
    "    if len(stopwords) > 0:\n",
    "        removed_lines = []\n",
    "        for line in list_lines:\n",
    "            for stopword in stopwords:\n",
    "                line = re.sub(stopword, '', line)\n",
    "            removed_lines.append(line)\n",
    "\n",
    "    # remove newlines\n",
    "    removed_lines = [sentence.replace('\\n', '') for sentence in removed_lines]\n",
    "\n",
    "    # strip whitespace\n",
    "    removed_lines = [sentence.strip() for sentence in removed_lines]\n",
    "\n",
    "    # remove one letter items\n",
    "    removed_lines = [sentence for sentence in removed_lines if len(sentence) > 1]\n",
    "\n",
    "    return removed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_post_processed = post_process(list_to_use, stopwords)\n",
    "print(len(list_post_processed))\n",
    "\n",
    "n = 10\n",
    "sampling(list_post_processed, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3900c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "# Load the Tokenizer: \"Fast\" means that the tokenizer code is written in Rust Lang\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the individual items in tokenized input_ids\n",
    "tokenized_input_ids = tokenizer(list_post_processed).input_ids\n",
    "tokenized_length = [len(item) for item in tokenized_input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config\n",
    "\n",
    "# set config and override with custom configuration\n",
    "config = GPT2Config.from_pretrained(CFG.model_dir)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9189970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# move the model to device\n",
    "if torch.cuda.is_available() and CFG.DEBUG == False:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif CFG.DEBUG == True:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"current device that is training on: {device}\")\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c32b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\" CustomDataset class for poetic sentences \"\"\"\n",
    "    def __init__(self, list_dataset, tokenizer):\n",
    "\n",
    "        self.list_dataset = list_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenized_sentences = self.tokenizer(\n",
    "            list_dataset,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=CFG.max_token_length,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded_dict = {key: val[idx] for key, val in self.tokenized_sentences.items()}\n",
    "        encoded_dict[\"labels\"] = encoded_dict[\"input_ids\"].clone() # gpt has same labels as input_ids: https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "        return encoded_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_post_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_poetic_dataset = CustomDataset(list_post_processed, tokenizer)\n",
    "kor_eval_dataset_for_debugging = CustomDataset(list_post_processed[:100], tokenizer) # small dataset for debugging purpose\n",
    "print(len(kor_poetic_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b24f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Jul  5 2022, 00:11:45) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d670fa2da9d1771f2ce22d800891e4db2c4301e4bd2d4d6dfd0558e6ef11b197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
